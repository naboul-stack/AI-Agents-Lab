{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use other models with the Azure AI Agent Service\n",
    "\n",
    "The Azure AI Agent Service also supports the following models from the Azure AI Foundry model catalog:\n",
    "* Llama 3.1-70B-instruct\n",
    "* Mistral-large-2407\n",
    "* Cohere command R+\n",
    "\n",
    "**In order to deploy these models the subcription need to have a payment method, because it will be transacted trough marketplace. Unfortunately the subscriptions for this workshop don't allow that, and in this case it is not possible to fully execute this lab.**\n",
    "\n",
    "\n",
    "Now let's create agents using Llama 3 in Azure AI Agents Service. To get started: \n",
    "1. Go to ai.azure.com and select **Model catalog** in the left navigation menu, and scroll down to **Meta-Llama-3-70B-Instruct**. You can also use  this link.  \n",
    "\n",
    "2. Select **Deploy**. \n",
    "\n",
    "3. In the Deployment options screen that appears, select Serverless API with Azure AI Content Safety. \n",
    "\n",
    "    ![An image of the llama model project selection  screen](./assets/img/llama-deployment.png)\n",
    " \n",
    "4. Select your project and click **Subscribe and deploy**. \n",
    "\n",
    "     ![An image of the llama model deployment screen](./assets/img/llama-deployment-2.png)\n",
    "\n",
    "5. Add the Serverless connection to your hub / project. The deployment name you choose will be the one you reference in your code.  \n",
    "\n",
    "6. When calling agent creation API, set the `models` parameter to your deployment name. For example:\n",
    "\n",
    "    \n",
    "    ```python\n",
    "    agent = project_client.agents.create_agent( model=\"llama-3\", name=\"my-agent\", instructions=\"You are a helpful agent\" ) \n",
    "    ```\n",
    "\n",
    "Feel free to test with other models\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
